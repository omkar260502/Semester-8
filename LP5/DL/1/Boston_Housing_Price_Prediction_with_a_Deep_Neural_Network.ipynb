{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "**Linear regression by using Deep Neural network**: Implement Boston housing price prediction problem by Linear regression using Deep Neural network. Use Boston House price prediction dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOTzZhdR9zZt"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_F2vhnLJ3lm6"
   },
   "outputs": [],
   "source": [
    "# Data analysis and visualization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhqBbskr-iag"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILfTB4Ow3OAU",
    "outputId": "96cf0938-0070-41b5-d59d-d32f2fda7e6e"
   },
   "outputs": [],
   "source": [
    "(X_train , y_train), (X_test , y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "                                            path = 'boston_housing_npz',\n",
    "                                            test_split = 0.15,\n",
    "                                            seed = 42\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHPrTJsyHKSO"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFxpm9uu-mcs"
   },
   "source": [
    "## Initial Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmgYsStF3vyi",
    "outputId": "d9d7c9ad-7e0a-4d0e-9c71-e20775ea9dc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((430, 13), numpy.ndarray),\n",
       " ((76, 13), numpy.ndarray),\n",
       " ((430,), numpy.ndarray),\n",
       " ((76,), numpy.ndarray))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data shape and type\n",
    "(X_train.shape, type(X_train)), (X_test.shape, type(X_test)), (y_train.shape, type(y_train)), (y_test.shape, type(y_test)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "-QVH6Dcl37Dl",
    "outputId": "860b6d19-12bf-4db1-a0bb-f579a0e671f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.279</td>\n",
       "      <td>74.5</td>\n",
       "      <td>4.0522</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>373.66</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.31827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.2</td>\n",
       "      <td>3.9986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>390.70</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.29090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.174</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.08</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.03841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.229</td>\n",
       "      <td>90.7</td>\n",
       "      <td>3.0993</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.33</td>\n",
       "      <td>12.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1      2    3      4      5     6       7     8      9     10  \\\n",
       "0  0.09178   0.0   4.05  0.0  0.510  6.416  84.1  2.6463   5.0  296.0  16.6   \n",
       "1  0.05644  40.0   6.41  1.0  0.447  6.758  32.9  4.0776   4.0  254.0  17.6   \n",
       "2  0.10574   0.0  27.74  0.0  0.609  5.983  98.8  1.8681   4.0  711.0  20.1   \n",
       "3  0.09164   0.0  10.81  0.0  0.413  6.065   7.8  5.2873   4.0  305.0  19.2   \n",
       "4  5.09017   0.0  18.10  0.0  0.713  6.297  91.8  2.3682  24.0  666.0  20.2   \n",
       "5  0.10153   0.0  12.83  0.0  0.437  6.279  74.5  4.0522   5.0  398.0  18.7   \n",
       "6  0.31827   0.0   9.90  0.0  0.544  5.914  83.2  3.9986   4.0  304.0  18.4   \n",
       "7  0.29090   0.0  21.89  0.0  0.624  6.174  93.6  1.6119   4.0  437.0  21.2   \n",
       "8  4.03841   0.0  18.10  0.0  0.532  6.229  90.7  3.0993  24.0  666.0  20.2   \n",
       "9  0.22438   0.0   9.69  0.0  0.585  6.027  79.7  2.4982   6.0  391.0  19.2   \n",
       "\n",
       "       11     12  \n",
       "0  395.50   9.04  \n",
       "1  396.90   3.53  \n",
       "2  390.11  18.07  \n",
       "3  390.91   5.52  \n",
       "4  385.09  17.27  \n",
       "5  373.66  11.97  \n",
       "6  390.70  18.33  \n",
       "7  388.08  24.16  \n",
       "8  395.33  12.87  \n",
       "9  396.90  14.33  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Data to DataFrame \n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "# Preview the training data\n",
    "X_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtocpgHS6zUg",
    "outputId": "874e6070-2117-49b5-968e-44f980f9219e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 430 entries, 0 to 429\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       430 non-null    float64\n",
      " 1   1       430 non-null    float64\n",
      " 2   2       430 non-null    float64\n",
      " 3   3       430 non-null    float64\n",
      " 4   4       430 non-null    float64\n",
      " 5   5       430 non-null    float64\n",
      " 6   6       430 non-null    float64\n",
      " 7   7       430 non-null    float64\n",
      " 8   8       430 non-null    float64\n",
      " 9   9       430 non-null    float64\n",
      " 10  10      430 non-null    float64\n",
      " 11  11      430 non-null    float64\n",
      " 12  12      430 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 43.8 KB\n",
      "________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 430 entries, 0 to 429\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       430 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.5 KB\n"
     ]
    }
   ],
   "source": [
    "# View summary of datasets\n",
    "X_train_df.info()\n",
    "print('_'*40)\n",
    "y_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "CeeFStx68vMP",
    "outputId": "887bb519-8460-4c38-f52a-e7c65e66a221"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.699248</td>\n",
       "      <td>11.588372</td>\n",
       "      <td>11.195209</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.553655</td>\n",
       "      <td>6.286177</td>\n",
       "      <td>68.624651</td>\n",
       "      <td>3.810942</td>\n",
       "      <td>9.604651</td>\n",
       "      <td>408.627907</td>\n",
       "      <td>18.460465</td>\n",
       "      <td>357.523140</td>\n",
       "      <td>12.735442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.914104</td>\n",
       "      <td>24.025489</td>\n",
       "      <td>6.908886</td>\n",
       "      <td>0.255051</td>\n",
       "      <td>0.116063</td>\n",
       "      <td>0.712024</td>\n",
       "      <td>28.262619</td>\n",
       "      <td>2.140100</td>\n",
       "      <td>8.722982</td>\n",
       "      <td>169.765535</td>\n",
       "      <td>2.155823</td>\n",
       "      <td>90.888664</td>\n",
       "      <td>7.234809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.137000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448250</td>\n",
       "      <td>5.881000</td>\n",
       "      <td>43.875000</td>\n",
       "      <td>2.091150</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.912500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.250895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.211500</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>3.190950</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.770000</td>\n",
       "      <td>11.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.628750</td>\n",
       "      <td>94.300000</td>\n",
       "      <td>5.226975</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.192500</td>\n",
       "      <td>17.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  430.000000  430.000000  430.000000  430.000000  430.000000  430.000000   \n",
       "mean     3.699248   11.588372   11.195209    0.069767    0.553655    6.286177   \n",
       "std      8.914104   24.025489    6.908886    0.255051    0.116063    0.712024   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082102    0.000000    5.190000    0.000000    0.448250    5.881000   \n",
       "50%      0.250895    0.000000    9.690000    0.000000    0.538000    6.211500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.628750   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  430.000000  430.000000  430.000000  430.000000  430.000000  430.000000   \n",
       "mean    68.624651    3.810942    9.604651  408.627907   18.460465  357.523140   \n",
       "std     28.262619    2.140100    8.722982  169.765535    2.155823   90.888664   \n",
       "min      2.900000    1.137000    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     43.875000    2.091150    4.000000  279.500000   17.400000  375.912500   \n",
       "50%     76.800000    3.190950    5.000000  330.000000   19.100000  391.770000   \n",
       "75%     94.300000    5.226975   24.000000  666.000000   20.200000  396.192500   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  430.000000  \n",
       "mean    12.735442  \n",
       "std      7.234809  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.465000  \n",
       "75%     17.117500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of numerical feature values across the samples\n",
    "X_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S3DE2_c_8j2"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "JEXlXchREDC6",
    "outputId": "891b630d-c9f4-4c11-9f09-dbbf883324d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.041508</td>\n",
       "      <td>0.115884</td>\n",
       "      <td>0.393519</td>\n",
       "      <td>0.347027</td>\n",
       "      <td>0.522165</td>\n",
       "      <td>0.676876</td>\n",
       "      <td>0.243318</td>\n",
       "      <td>0.374115</td>\n",
       "      <td>0.422954</td>\n",
       "      <td>0.623454</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.303682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.100192</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.253258</td>\n",
       "      <td>0.238812</td>\n",
       "      <td>0.136429</td>\n",
       "      <td>0.291067</td>\n",
       "      <td>0.194740</td>\n",
       "      <td>0.379260</td>\n",
       "      <td>0.323980</td>\n",
       "      <td>0.229343</td>\n",
       "      <td>0.229181</td>\n",
       "      <td>0.199636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.130144</td>\n",
       "      <td>0.444530</td>\n",
       "      <td>0.421988</td>\n",
       "      <td>0.086824</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.176527</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.947079</td>\n",
       "      <td>0.144040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338343</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.761071</td>\n",
       "      <td>0.186901</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.272901</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.987064</td>\n",
       "      <td>0.268626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041258</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.646628</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>0.587804</td>\n",
       "      <td>0.941298</td>\n",
       "      <td>0.372171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.998216</td>\n",
       "      <td>0.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  430.000000  430.000000  430.000000  430.000000  430.000000  430.000000   \n",
       "mean     0.041508    0.115884    0.393519    0.347027    0.522165    0.676876   \n",
       "std      0.100192    0.240255    0.253258    0.238812    0.136429    0.291067   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000852    0.000000    0.173387    0.130144    0.444530    0.421988   \n",
       "50%      0.002749    0.000000    0.338343    0.314815    0.507856    0.761071   \n",
       "75%      0.041258    0.125000    0.646628    0.491770    0.587804    0.941298   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \n",
       "count  430.000000  430.000000  430.000000  430.000000  430.000000  430.000000  \n",
       "mean     0.243318    0.374115    0.422954    0.623454    0.900709    0.303682  \n",
       "std      0.194740    0.379260    0.323980    0.229343    0.229181    0.199636  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.086824    0.130435    0.176527    0.510638    0.947079    0.144040  \n",
       "50%      0.186901    0.173913    0.272901    0.691489    0.987064    0.268626  \n",
       "75%      0.372171    1.000000    0.914122    0.808511    0.998216    0.424600  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    ")\n",
    "\n",
    "# Normalization and data type change\n",
    "X_train = ct.fit_transform(X_train).astype('float32')\n",
    "# X_test = ct.transform(X_test).astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "# y_test = y_test.astype('float32')\n",
    "\n",
    "# Distribution of X_train feature values after normalization\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwbgGLK9FyRG"
   },
   "source": [
    "# Model, Predict, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yG6aN-_RDxF",
    "outputId": "dcf22498-58a2-405e-f110-e0def71cd652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((387, 12), (43, 12), (387,), (43,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXXjkEnchKQ0"
   },
   "source": [
    "## Creating the Model and Optimizing the Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wt3qQohTiNK8"
   },
   "source": [
    "learning rate = 0.01,\n",
    "batch_size = 32,\n",
    "dense_layers = 2,\n",
    "hidden_units for Dense_1 layer= 10,\n",
    "hidden_units for Dense_2 layer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxuLioVJHXep",
    "outputId": "db41144b-fcda-4412-d658-e8c7b4b48129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 454.1173 - mse: 454.1173 - val_loss: 92.7618 - val_mse: 92.7618\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 96.5716 - mse: 96.5716 - val_loss: 46.9142 - val_mse: 46.9142\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 58.0000 - mse: 58.0000 - val_loss: 33.9339 - val_mse: 33.9339\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 47.0787 - mse: 47.0787 - val_loss: 28.9487 - val_mse: 28.9487\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.7604 - mse: 39.7604 - val_loss: 25.4224 - val_mse: 25.4224\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.3562 - mse: 34.3562 - val_loss: 22.4692 - val_mse: 22.4692\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.3024 - mse: 30.3024 - val_loss: 20.2377 - val_mse: 20.2377\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6426 - mse: 27.6426 - val_loss: 18.0233 - val_mse: 18.0233\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25.8982 - mse: 25.8982 - val_loss: 16.5034 - val_mse: 16.5034\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.9443 - mse: 24.9443 - val_loss: 16.0871 - val_mse: 16.0871\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24.1736 - mse: 24.1736 - val_loss: 16.0412 - val_mse: 16.0412\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.4559 - mse: 23.4559 - val_loss: 16.0228 - val_mse: 16.0228\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.3903 - mse: 23.3903 - val_loss: 15.9977 - val_mse: 15.9977\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.9511 - mse: 22.9511 - val_loss: 15.9707 - val_mse: 15.9707\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.5118 - mse: 22.5118 - val_loss: 16.2094 - val_mse: 16.2094\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.5820 - mse: 22.5820 - val_loss: 15.7662 - val_mse: 15.7662\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.3163 - mse: 22.3163 - val_loss: 15.5413 - val_mse: 15.5413\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.1148 - mse: 22.1148 - val_loss: 15.1843 - val_mse: 15.1843\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.9325 - mse: 21.9325 - val_loss: 16.2436 - val_mse: 16.2436\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.7325 - mse: 21.7325 - val_loss: 14.9336 - val_mse: 14.9336\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.3116 - mse: 21.3116 - val_loss: 14.4049 - val_mse: 14.4049\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21.3817 - mse: 21.3817 - val_loss: 13.6296 - val_mse: 13.6296\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.9933 - mse: 20.9933 - val_loss: 13.4643 - val_mse: 13.4643\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.6002 - mse: 20.6002 - val_loss: 13.1095 - val_mse: 13.1095\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.3727 - mse: 20.3727 - val_loss: 13.0969 - val_mse: 13.0969\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.0836 - mse: 20.0836 - val_loss: 14.0241 - val_mse: 14.0241\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.9951 - mse: 19.9951 - val_loss: 12.8532 - val_mse: 12.8532\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.4852 - mse: 19.4852 - val_loss: 12.1285 - val_mse: 12.1285\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.1338 - mse: 19.1338 - val_loss: 11.8914 - val_mse: 11.8914\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.0781 - mse: 19.0781 - val_loss: 11.6698 - val_mse: 11.6698\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.6392 - mse: 18.6392 - val_loss: 11.1265 - val_mse: 11.1265\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.9240 - mse: 17.9240 - val_loss: 10.6766 - val_mse: 10.6766\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.3561 - mse: 17.3561 - val_loss: 10.1483 - val_mse: 10.1483\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.5888 - mse: 16.5888 - val_loss: 9.8505 - val_mse: 9.8505\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.1121 - mse: 15.1121 - val_loss: 20.2666 - val_mse: 20.2666\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.8060 - mse: 20.8060 - val_loss: 9.7900 - val_mse: 9.7900\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6957 - mse: 15.6957 - val_loss: 10.5949 - val_mse: 10.5949\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.9561 - mse: 15.9561 - val_loss: 9.7914 - val_mse: 9.7914\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.1952 - mse: 16.1952 - val_loss: 10.5426 - val_mse: 10.5426\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.1989 - mse: 17.1989 - val_loss: 9.6927 - val_mse: 9.6927\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.8745 - mse: 14.8745 - val_loss: 10.6856 - val_mse: 10.6856\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.7753 - mse: 15.7753 - val_loss: 9.7842 - val_mse: 9.7842\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6016 - mse: 15.6016 - val_loss: 10.6938 - val_mse: 10.6938\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.4310 - mse: 16.4310 - val_loss: 9.8059 - val_mse: 9.8059\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.7262 - mse: 14.7262 - val_loss: 10.6770 - val_mse: 10.6770\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.9950 - mse: 14.9950 - val_loss: 9.9267 - val_mse: 9.9267\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.2297 - mse: 15.2297 - val_loss: 10.7087 - val_mse: 10.7087\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.7036 - mse: 15.7036 - val_loss: 10.0132 - val_mse: 10.0132\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 14.1193 - mse: 14.1193 - val_loss: 11.1300 - val_mse: 11.1300\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.7568 - mse: 15.7568 - val_loss: 10.0506 - val_mse: 10.0506\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Building the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(units=10, activation='relu', input_shape=(X_train.shape[1],), name='Dense_1'),\n",
    "  tf.keras.layers.Dense(units=100, activation='relu', name='Dense_2'),\n",
    "  tf.keras.layers.Dense(units=1, name='Prediction')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.mean_squared_error,\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
    "    metrics = ['mse']\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VasQEdJRe9NK"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1t-7HcflKgGV",
    "outputId": "71e123d7-73d3-4d6e-97d9-3a6aa6774076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.765375, 20.558142)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the mean value of training and validation data\n",
    "y_train.mean(), y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4F5mom8FfACb",
    "outputId": "1577826d-50d7-47a8-ab8c-d423d52be46e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Test data \n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1_1/Dense_1_1/Relu defined at (most recent call last):\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15848\\967386007.py\", line 3, in <cell line: 3>\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 425, in evaluate\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 161, in one_step_on_iterator\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 150, in one_step_on_data\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 78, in test_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\layer.py\", line 842, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\models\\sequential.py\", line 206, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\models\\functional.py\", line 199, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\ops\\function.py\", line 151, in _run_through_graph\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\models\\functional.py\", line 589, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\layer.py\", line 842, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 154, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\activations\\activations.py\", line 47, in relu\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\activations\\activations.py\", line 99, in static_call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 17, in relu\n\nMatrix size-incompatible: In[0]: [32,13], In[1]: [12,10]\n\t [[{{node sequential_1_1/Dense_1_1/Relu}}]] [Op:__inference_one_step_on_iterator_11535]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation on Test data \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m loss, mse \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel loss on test set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel mean squared error on test set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(mse)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_1_1/Dense_1_1/Relu defined at (most recent call last):\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n\n  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15848\\967386007.py\", line 3, in <cell line: 3>\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 425, in evaluate\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 161, in one_step_on_iterator\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 150, in one_step_on_data\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 78, in test_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\layer.py\", line 842, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\models\\sequential.py\", line 206, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\models\\functional.py\", line 199, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\ops\\function.py\", line 151, in _run_through_graph\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\models\\functional.py\", line 589, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\layer.py\", line 842, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 154, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\activations\\activations.py\", line 47, in relu\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\activations\\activations.py\", line 99, in static_call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 17, in relu\n\nMatrix size-incompatible: In[0]: [32,13], In[1]: [12,10]\n\t [[{{node sequential_1_1/Dense_1_1/Relu}}]] [Op:__inference_one_step_on_iterator_11535]"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "print(\"Evaluation on Test data \\n\")\n",
    "loss, mse = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"\\nModel loss on test set: {loss}\")\n",
    "print(f\"Model mean squared error on test set: {(mse):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "1CD_HeZ1LFZ5",
    "outputId": "4caf3820-2be3-421d-9826-600baf83d452"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "pd.DataFrame(history.history).plot(figsize=(6, 4), xlabel=\"Epochs\", ylabel=\"Loss\", title='Loss Curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wsto_sf8fXM-"
   },
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrKgnaZpfmJI",
    "outputId": "acd18217-d775-4d3a-b901-e490d8628d6f"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"Dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 12, but received input with shape (32, 13)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 13), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# View the first prediction\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_pred[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"Dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 12, but received input with shape (32, 13)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 13), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# View the first prediction\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Boston_Housing_Price_Prediction_with_a_Deep_Neural_Network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
